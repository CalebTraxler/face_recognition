# -*- coding: utf-8 -*-
"""facerecog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PN-ZxxCelXr27UXF4rTd34IaeBoBni7f

#Installing Dependencies without a tensorflow.gpu
"""

!pip install tensorflow==2.16.1 opencv-python matplotlib

"""Importing Dependencies"""

import cv2 # Import open cv into notebook.
import os # Operating system library.
import random # Optional - If testing / generating data, comes in handy.
import numpy as np # Helps work with tensors and workign with arrays.
from matplotlib import pyplot as plt #Want to use plot.imshow to see images.

# Import tensorflow dependencies
# One show classification via a siamese neural network...?
# View this research paper for more information about siamese neural networks when working with image recognition.
# Paper link: https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
# Two inputs: passing in two images at the same time. There exists a distance layer, which will then test the similarities
# betweent the two images.
# Very similar -> output a 1
# Very different -> output a 0

#Importing functional API components

from tensorflow.keras.models import Model #Allows us to do something like Model(inputs=[inputs, verificationimage], outputs=[1,0])
from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten #Conv. NN tools
import tensorflow as tf

# If ther exists a GPU, run this block: Memory ocnsumption growth setup
gpus = tf.config.experimental.list_physical_devices('GPU') #accessing all gpus on the machine.
for gpu in gpus:
    tf.config.experimental.set_memory_groeth(gpu, True)

POS_PATH = os.path.join('data', 'positive') # returns data\\positive
NEG_PATH = os.path.join('data', 'negative') # returns data\\negative
ANC_PATH = os.path.join('data', 'anchor') # returns data\\anchor

# Making directories in the file directory
os.makedirs(POS_PATH)
os.makedirs(NEG_PATH)
os.makedirs(ANC_PATH)

# Now im going to collect the images via the image data. Recall that I need 3 different categories image data
# Positive images, negative inages and anchor images.
# 1. Anchor (Input Image, in this case from webcam) into a model encoding, compared to
# 2. Positive (Pos. Image) into the model encoding and comparing the two.
# Via siamese NN,  we pass both into a distance layer to see how similar they are, which in return will output 1 or a 0
# If 1, then the person in webcam is the same person in the positive image.

# Similar process for the negatvie case, however the distance layer will then output a 0

"""HUGE NOTE: We will only be using a single person (me) for the anchor. However we can (if desired) implement the same program for multiple people.

"""

# Now , I will perform some data collection for the anchors, positive and negative image data.
# Recall: Anchor data will come from the webcam (using the OpenCV package)
# Positive data will also some from the webcam
# Negative data will come from the labelled faces in a wild dataset.

# For negative faces, here is the data set: http://vis-www.cs.umass.edu/Lfw/
# Download the one titled "All images as gzipped tar file" 173 MB

# Untar the labelled faces in the Wild Dataset
!tar -xf lfw.tgz

# Move the Images into the following repository data/negative
for directory in os.listdir('lfw'):
    for file in os.listdir(os.path.join('lfw', directory)):
        EX_PATH = os.path.join('lfw', directory, file)
        NEW_PATH = os.path.join(NEG_PATH, file)
        os.replace(EX_PATH, NEW_PATH)

# Now using openCV, I will collect data though my webcam.
# Note that I only want to collect images of size 250x250 pixels, to match the size of the iamges in the LFW data set.

# Data Collection for anchor and positive folders. I collected about 400 images per folder.
# Note that you should only run this function once per every 15 images per folder, i.e. run this function approximately 27 times. (sorry)
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
from PIL import Image as PilImage
import os
import time
from io import BytesIO

# Directory paths
anchor_path = "/content/data/anchor"
positive_path = "/content/data/positive"
os.makedirs(anchor_path, exist_ok=True)
os.makedirs(positive_path, exist_ok=True)

def take_photos(quality=0.8):
    js = Javascript('''
    async function takePhotos(quality) {
        const div = document.createElement('div');
        const captureAnchor = document.createElement('button');
        captureAnchor.textContent = 'Capture Anchor';
        const capturePositive = document.createElement('button');
        capturePositive.textContent = 'Capture Positive';
        const stop = document.createElement('button');
        stop.textContent = 'Stop';
        div.appendChild(captureAnchor);
        div.appendChild(capturePositive);
        div.appendChild(stop);

        document.body.appendChild(div);

        const video = document.createElement('video');
        video.style.display = 'block';
        const stream = await navigator.mediaDevices.getUserMedia({video: true});
        div.appendChild(video);
        video.srcObject = stream;
        await video.play();

        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

        let photos = [];

        captureAnchor.onclick = () => capture('anchor');
        capturePositive.onclick = () => capture('positive');

        function capture(type) {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            const dataUrl = canvas.toDataURL('image/jpeg', quality);
            photos.push({type: type, dataUrl: dataUrl});
        }

        stop.onclick = () => {
            stream.getVideoTracks()[0].stop();
            div.remove();
            return photos;
        };

        return new Promise((resolve) => stop.addEventListener('click', () => resolve(photos)));
    }
    ''')
    display(js)
    return eval_js('takePhotos({})')

def save_photos(photo_data):
    counter = 1  # Initialize a counter to ensure unique filenames
    for data in photo_data:
        binary = b64decode(data['dataUrl'].split(',')[1])
        img = PilImage.open(BytesIO(binary))

        # Crop and resize the image
        crop_area = (200, 120, 450, 370)  # Adjusted to crop the specific area
        cropped_img = img.crop(crop_area)
        resized_img = cropped_img.resize((250, 250), PilImage.ANTIALIAS)

        directory = f"/content/data/{data['type']}"
        timestamp = int(time.time())
        filename = f"{directory}/{timestamp}_{counter}.jpg"
        resized_img.save(filename)  # Save the cropped and resized image
        print(f"Saved {filename}")
        counter += 1

# Capture and save the photos
photo_data = take_photos()
save_photos(photo_data)

import os

folder_path = '/content/data/positive'
num_files = len([name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))])
print(num_files)

# Now want to use a tensorflow data loader to process the images using data pipelines
# First get the images
# Using a wildcard, grab everything in the file path with a jpg extension and store into the variable.
# Also note that we want a matching number of samples for each data variables
anchor  = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(400)
positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(400)
negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(400)

dir_test = anchor.as_numpy_iterator()

dir_test.next()

# Now I want to proprocess all of my image data to make the gradient descent and
# the machine learning process easier.

# This function will scale and re-size the data using a map method, re-scaling image between 0 and 1.
def preprocess(file_path):

    # Read in image from file path
    byte_img = tf.io.read_file(file_path)

    # Load in the image
    img = tf.io.decode_jpeg(byte_img)

    # Preprocessing steps - re-sizing the iamge to be 100x100x3
    img = tf.image.resize(img, (100,100))
    # Scale image to be between 0 and 1
    img = img / 255.0
    #Returning image
    return img

img = preprocess('data/anchor/1712436367_13.jpg')

plt.imshow(img)

# Now I want to create the labelled datasets. 1 for positives and 0 for negatives
positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))
negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))
data = positives.concatenate(negatives)

# Now I want to build, train and test partition.
def preprocess_twin(input_img, validation_img, label):
    return(preprocess(input_img), preprocess(validation_img), label)

# Building the data pipeline... last prep for training
data = data.map(preprocess_twin)
data = data.cache()
data = data.shuffle(buffer_size = 1024)

# Creating a training partition
train_data = data.take(round(len(data)*.7))
train_data = train_data.batch(16)
train_data = train_data.prefetch(8)

# Creating a Testing Partition
test_data = data.skip(round(len(data)*.7))
test_data = test_data.take(round(len(data)*.3))
test_data = test_data.batch(16)
test_data = test_data.prefetch(8)

"""**Machine Learning Portion - **

Building an embedding layer

Creating an L1 Distance Layer

Compile the Siamese Network
"""

# Function that builds the embedding layer
# ReLU activation, takes 64 pixels, with filter of 10x10, stride = 1
# Recall the paper for the specific convolutions, activations functions and dimensions
# Sequence: inp->c1->m1->c2->m2->c3->m3->c4->f1->d1
def make_embedding():
    #Input
    inp = Input(shape=(100,100,3), name='input_image')

    #First Block
    # Convolution with ReLU activation
    c1 = Conv2D(64, (10,10), activation = 'relu')(inp)
    # MaxPooling
    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)

    #Second Block
    c2 = Conv2D(128, (7,7), activation='relu')(m1)
    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)

    #Third Block
    c3 = Conv2D(128, (4,4), activation='relu')(m2)
    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)

    #Fourth Block
    c4 = Conv2D(256, (4,4), activation='relu')(m3)
    f1 = Flatten()(c4)
    d1 = Dense(4096, activation='sigmoid')(f1)

    return Model(inputs=[inp], outputs=[d1], name='embedding')

#Summary of the entire convolution.

#First Block
inp = Input(shape=(100,100,3), name='input_image')
# Convolution with ReLU activation
c1 = Conv2D(64, (10,10), activation = 'relu')(inp)
# MaxPooling
m1 = MaxPooling2D(64, (2,2), padding='same')(c1)

#Second Block
c2 = Conv2D(128, (7,7), activation='relu')(m1)
m2 = MaxPooling2D(64, (2,2), padding='same')(c2)

#Third Block
c3 = Conv2D(128, (4,4), activation='relu')(m2)
m3 = MaxPooling2D(64, (2,2), padding='same')(c3)

#Fourth Block
c4 = Conv2D(256, (4,4), activation='relu')(m3)
f1 = Flatten()(c4)
d1 = Dense(4096, activation='sigmoid')(f1)

embedding = make_embedding()

embedding.summary()

class L1Dist(Layer):
    def __init__(self, **kwargs):
        super(L1Dist, self).__init__(**kwargs)

    def call(self, inputs):
        # Unpack the inputs list to individual tensors
        input_embedding, validation_embedding = inputs
        return tf.math.abs(tf.math.subtract(input_embedding, validation_embedding))

def make_siamese_model():
    # Anchor image input in the network
    input_image = Input(name='input_img', shape=(100, 100, 3))

    # Validation image in the network
    validation_image = Input(name='validation_img', shape=(100, 100, 3))

    # Process both inputs through the same embedding model
    anchor_embedding = embedding(input_image)
    validation_embedding = embedding(validation_image)

    # Combine siamese distance components
    siamese_layer = L1Dist()
    distances = siamese_layer([anchor_embedding, validation_embedding])  # Correctly pass inputs as a list

    # Classification Layer
    classifier = Dense(1, activation='sigmoid')(distances)

    # Construct and return the Siamese Network model
    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')

siamese_model = make_siamese_model()

siamese_model.summary()

"""Now I want to set up a loss function, set up an optimizer, build a custom training setup and train the model."""

# Setting up the loss function and optimizer
# What if logits = true??? No because our values are already floats for the resulting probabilities.
binary_cross_loss = tf.losses.BinaryCrossentropy()

# Now, lets define our optimizer, here I will use an Adam optimizer with a learning rate of 1e-4
opt = tf.keras.optimizers.Adam(1e-4)

# Now, Im going to establish a checkpoint callback
# Note that to reload from the checkpoint you can use model.load('path_to_checkpoint')
# The line above will load the pre traine weights into the existing model.
#Directory where we will save all of the checkpoints.
checkpoint_dir = './training_checkpoints'
#Prefix all checkpoints with 'ckpt'
checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')
#Saving opt and siamese_model as the checkpoints.
checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)

# Now I want to build / train using a step function.
# The flow for training on one batch is: prediction, calculate loss, derive gradiencts, calculate new weights and apply
@tf.function #Decorator - Compiles a function into a callable Tensorflow graph
def train_step(batch):

    #Records operations for automatic differentiation
    with tf.GradientTape() as tape:

        #Get anchor and positive/negative image
        X = batch[:2]
        #Get label
        y = batch[2]

        #Forward pass to the siamese neural network
        yhat = siamese_model(X, training=True)
        #Calculate the loss... want to pass a y_true value and a y_pred value, i.e. the actual y and the predicted y
        loss = binary_cross_loss(y, tf.squeeze(yhat))
    print(loss)

    #Now calcualte the gradients.
    grad = tape.gradient(loss, siamese_model.trainable_variables)

    #Calculate updated weights and apply to siamese model
    #Note that the optimizer here is calculating and propagating the new weights using Adams optimization algorithm , a varient of gradient descent.
    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))

    return loss

# Now I want to build the training loop
# Note that the train_step funciton was focused on training for one batch, the loop here will be used to iterate over every batch in the dataset.
def train(data, EPOCHS):
    #Loop though the EOPCHS
    for epoch in range(1, EPOCHS+1):
        print('\n Epoch {}/{}'.format(epoch, EPOCHS))
        progbar = tf.keras.utils.Progbar(len(data))

    #Loop though each batch
    for idx, batch in enumerate(data):
        #Run train step here.
        train_step(batch)
        progbar.update(idx+1)

    #Save checkpoints approximately every  10 epochs
    if epoch % 10 == 0:
        checkpoint.save(file_prefix=checkpoint_prefix)

# Now lets train the model
EPOCHS = 50

train(train_data, EPOCHS)

"""Now I want to test the model, evaluate the perfomance and save the model for deployment."""

#Now I want to evaluate the model using precision and recall.
#Im not going to import the required packages
#Precision demonstrates what proportion of positive identifications were actually correct.
#Recall shows what proportion of actual positives were identified correctly.
from tensorflow.keras.metrics import Precision, Recall

# Get a batch of test data
test_input, test_val, y_true = test_data.as_numpy_iterator().next()

# Making predictions.
y_hat = siamese_model.predict([test_input, test_val])
y_hat

# Post processing the results.
processed_results = [[1 if element > 0.5 else 0 for element in prediction] for prediction in y_hat]
processed_results

y_true

"""THESE MATCH VERY VERY WELL!

"""

# Creating a metric object for recall
r = Recall()

#Update the state, or calculating the recall value, passing y_true and y_hat
r.update_state(y_true, y_hat)

#Accessing the result, converting to a numpy value
print('recall:', r.result().numpy())

##############

#Similar metric for precision

# Creating a metric object for precision
p = Precision()

#Update the state, or calculating the precision value, passing y_true and y_hat
p.update_state(y_true, y_hat)

#Accessing the result, converting to a numpy value
print('precision:', p.result().numpy())

"""^^ if 1.0, this implies 100%, which was what I got.

HUGE NOTE: This was the result for a single batch...
"""

# Lets visual the results now.
 plt.figure(figsize=(10,8))
 plt.subplot(1,2,1)
 plt.imshow(test_input[0])
 plt.subplot(1,2,2)
 plt.imshow(test_val[0])
 plt.show()

# Lets visual the results now.
 plt.figure(figsize=(10,8))
 plt.subplot(1,2,1)
 plt.imshow(test_input[2])
 plt.subplot(1,2,2)
 plt.imshow(test_val[2])
 plt.show()

#Now I want to save the model
#Save the weights
siamese_model.save('siamesemodel.h5')

# Reloading the model
siamese_model.load_weights

siamese_model.predict([test_input, test_val])